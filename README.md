<h1 align="center">Automatic Weapon Detection</h1>
<p align="center"><i>Deployment of a hybrid model for automatic weapon detection/ anomaly detection for surveillance applications.</i></p>
<div align="center"><p align="center">
  <a href="https://github.com/Janhavi404/Automatic-Weapon-Detection"><img src="https://img.shields.io/github/stars/Janhavi404/Automatic-Weapon-Detection" alt="Stars Badge"/></a>
  <a href="https://github.com/Janhavi404/Automatic-Weapon-Detection"><img src="https://img.shields.io/github/forks/Janhavi404/Automatic-Weapon-Detection" alt="Forks Badge"/></a>
  <a href="https://github.com/Janhavi404/Automatic-Weapon-Detection"><img src="https://img.shields.io/github/issues-pr/Janhavi404/Automatic-Weapon-Detection" alt="Pull Requests Badge"/></a>
  <a href="https://github.com/Janhavi404/Automatic-Weapon-Detection"><img src="https://img.shields.io/github/issues/Janhavi404/Automatic-Weapon-Detection" alt="Issues Badge"/></a>
  <a href="https://github.com/Janhavi404/Automatic-Weapon-Detection/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/Janhavi404/Automatic-Weapon-Detection"></a>
  <a href=""><img src="https://img.shields.io/github/license/Janhavi404/Automatic-Weapon-Detection?color=2b9348" alt="License   Badge"/></a></p>
</div>
<br>
<p align="center"><i>Loved the project? Please visit our <a href="#">Website</a></i></p>
<br>

## Literature Survey
Security is always a main concern in every domain, due to a rise in crime rate in a crowded event or suspicious lonely areas. Weapon detection and monitoring have major applications of computer vision to tackle various problems. Due to growing demand in the protection of safety, security and personal properties, needs and deployment of video surveillance systems can recognize and interpret the scene and anomaly events play a vital role in intelligence monitoring. We implemented weapon detection using a convolution neural network (CNN). Results are tabulated, both algorithms achieve good accuracy, but their application in real situations can be based on the trade-off between speed and accuracy. 
We surveyed various research evidences and proposed a detection framework which involves three phases detection of objects, recognition of detected objects and alarm system. Single learning based detection framework is used because of  which high  processing speed is achieved. Because dense features need only to  be  evaluated  once  rather  than individually  for  each  detector.  For object detection a framework using a linear support vector machine  classifier  with  histogram  of  oriented  gradients features. Using a combination of ACF(Aggregated Channel Features)  features  and  sp-  LBP(Local  binary pattern)features  can  provide  a  better  trade-off  between detection  performance  and  system  runtime. some techniques are used to post-process raw detection results.  Uses  shrinkage  version  of  AdaBoost  as  the strong classiﬁer and use decision trees as weak learners.To train the classiﬁer, the procedure known as bootstrapping is applied . 
Shifu Zhou(researcher) et al suggested  a method for detecting  and locating anomalous activities in video sequences of crowded scenes. The key for method is the coupling of anomdescribon with a spatial-temporal Convolutional Neural Networks. This architecture allows us to capture features from both spatial and temporal dimensions by performing spatial-temporal convolutions,  thereby,  both  the  appearance  and  motion information  encoded in continuous  frames are  extracted Two criterions are used for evaluating anomaly detection accuracy namely a frame level criterion and a pixel level criterion. Motion pattern and FRP (False  positive  rates)  are  calculated  for  evaluating performance. And  DR(Detection Rate) corresponds  to the successful  detection  rate  of  the  anomalies  happening  at EER(Equal Error Rate). 
We also surveyed from various research evidences that  One of the main challenges is to detect anomalies both in time and space domains. This implies to find out which frames that anomalies occur and to localize regions that generate the anomalies within these frames. This model  extracts features from  both  the  spatial  and  the  temporal  dimensions  by performing. 3D convolutions, is achieved by convolving a 3D kernel to the cube formed by stacking multiple contiguous frames together. The issues  are that , accurate  recognition of actions  is  a  highly  challenging  task  due  to  cluttered backgrounds, occlusions, and viewpoint variations perform 3D convolution in the convolutional layers of CNNs so that discriminative  features  along  both  the  spatial  and  the temporal  dimensions  are  captured.3D  convolution  is achieved by stacking multiple contiguous frames together. The  developed  3D  CNN  model  was  trained  using  a supervised  algorithm ,  and  it  requires  a large  number of labelled samples. we propose a novel end-to-end model which integrates the one-class Support Vector Machine (SVM) into Convolutional Neural Network (CNN). Specifically, the robust loss function derived from the one-class SVM  is proposed  to optimize  the parameters  of this model. We proposed a learning  model  for  weapon  detection  from video sequences by combining CNN and SVM. CNN is utilized to learn the underlying high-dimensional normal representations to effectively capture normal features. SVM layer  not  only distinguishes  normal/abnormal cases as  a discriminator, but also optimizes parameters of the whole model as an optimization objective.
From our exhaustive study of work done and research about Weapon detection model , we proposed a Model which detects the Weapon from video or Picture and activates the alarm.



## Project Summary:
In this project CNN algorithm is simulated for pre-labelled image dataset for weapon (gun, knife) detection. The algorithm is efficient and gives good results but its application in real time is based on a trade-off between speed and accuracy. With respect to accuracy, CNN gives accuracy of approx. 85%. In our CNN model we have taken 16 layers. Apart from this the optimiser used by us is SGD, with categorical cross entropy loss and accuracy is used as the metrics. For every layer we have used the ‘relu’ activation function, for the last layer we have used softmax. We have used Tensorflow, Keras, PIL, OpenCV, Playsound modules to implement the project. Our software takes a 240 x 240 image as input, in a batch size of 32.

Further, it can be implemented for larger datasets by training using GPUs and high-end DSP and FPGA kits.
